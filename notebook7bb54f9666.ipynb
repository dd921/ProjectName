{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-03-28T12:31:47.886043Z","iopub.execute_input":"2023-03-28T12:31:47.886498Z","iopub.status.idle":"2023-03-28T12:31:47.928107Z","shell.execute_reply.started":"2023-03-28T12:31:47.886460Z","shell.execute_reply":"2023-03-28T12:31:47.926649Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/the-largest-diamond-dataset-currely-on-kaggle/diamonds.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:36:41.447725Z","iopub.execute_input":"2023-03-28T12:36:41.448144Z","iopub.status.idle":"2023-03-28T12:36:42.019574Z","shell.execute_reply.started":"2023-03-28T12:36:41.448111Z","shell.execute_reply":"2023-03-28T12:36:42.017690Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df.info()\n# df.head()\n# df = pd.read_csv('/kaggle/input/the-largest-diamond-dataset-currely-on-kaggle/diamonds.csv')","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:40:51.857703Z","iopub.execute_input":"2023-03-28T12:40:51.858165Z","iopub.status.idle":"2023-03-28T12:40:52.080437Z","shell.execute_reply.started":"2023-03-28T12:40:51.858130Z","shell.execute_reply":"2023-03-28T12:40:52.078894Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 219703 entries, 0 to 219702\nData columns (total 26 columns):\n #   Column                       Non-Null Count   Dtype  \n---  ------                       --------------   -----  \n 0   Unnamed: 0                   219703 non-null  int64  \n 1   cut                          219703 non-null  object \n 2   color                        219703 non-null  object \n 3   clarity                      219703 non-null  object \n 4   carat_weight                 219703 non-null  float64\n 5   cut_quality                  219703 non-null  object \n 6   lab                          219703 non-null  object \n 7   symmetry                     219703 non-null  object \n 8   polish                       219703 non-null  object \n 9   eye_clean                    219703 non-null  object \n 10  culet_size                   219703 non-null  object \n 11  culet_condition              219703 non-null  object \n 12  depth_percent                219703 non-null  float64\n 13  table_percent                219703 non-null  float64\n 14  meas_length                  219703 non-null  float64\n 15  meas_width                   219703 non-null  float64\n 16  meas_depth                   219703 non-null  float64\n 17  girdle_min                   219703 non-null  object \n 18  girdle_max                   219703 non-null  object \n 19  fluor_color                  219703 non-null  object \n 20  fluor_intensity              219703 non-null  object \n 21  fancy_color_dominant_color   219703 non-null  object \n 22  fancy_color_secondary_color  219703 non-null  object \n 23  fancy_color_overtone         219703 non-null  object \n 24  fancy_color_intensity        219703 non-null  object \n 25  total_sales_price            219703 non-null  int64  \ndtypes: float64(6), int64(2), object(18)\nmemory usage: 43.6+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"\n# Load the dataset into a Pandas dataframe\ndf = pd.read_csv('/kaggle/input/the-largest-diamond-dataset-currely-on-kaggle/diamonds.csv')\n\n\n# Convert categorical variables to numerical values using dummies\ncat_cols = ['cut', 'color', 'clarity', 'cut_quality', 'lab', 'symmetry',\n            'polish', 'eye_clean', 'culet_size', 'culet_condition',\n            'girdle_min', 'girdle_max', 'fluor_color',\n            'fluor_intensity', 'fancy_color_dominant_color',\n            'fancy_color_secondary_color', 'fancy_color_overtone',\n            'fancy_color_intensity']\ndf = pd.get_dummies(df, columns=cat_cols)\n\n# Prepare the data for modeling by splitting the dataset into training and testing sets\nX = df.drop(['total_sales_price'], axis=1)\ny = df['total_sales_price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train a linear regression model using scikit-learn\nreg = LinearRegression()\nreg.fit(X_train, y_train)\n\n# Evaluate the model using mean squared error and R-squared\ny_pred = reg.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"Mean Squared Error:\", mse)\nprint(\"R-squared:\", r2)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:41:36.549126Z","iopub.execute_input":"2023-03-28T12:41:36.549570Z","iopub.status.idle":"2023-03-28T12:41:40.732526Z","shell.execute_reply.started":"2023-03-28T12:41:36.549533Z","shell.execute_reply":"2023-03-28T12:41:40.730440Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Mean Squared Error: 265913402.08004013\nR-squared: 0.6576727832731184\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n\ndf = pd.read_csv('/kaggle/input/the-largest-diamond-dataset-currely-on-kaggle/diamonds.csv')\n\n# Convert categorical variables to numerical values using dummies\ncat_cols = ['cut', 'color', 'clarity', 'cut_quality', 'lab', 'symmetry', 'polish', 'eye_clean', 'culet_size', 'culet_condition', 'girdle_min', 'girdle_max', 'fluor_color', 'fluor_intensity', 'fancy_color_dominant_color', 'fancy_color_secondary_color', 'fancy_color_overtone', 'fancy_color_intensity']\ndf = pd.get_dummies(df, columns=cat_cols)\n\n# Prepare the data for modeling by splitting the dataset into training and testing sets\nX = df.drop(['total_sales_price'], axis=1)\ny = df['total_sales_price']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train an XGBoost model using the training data\nxgb_model = xgb.XGBRegressor(\n    objective ='reg:squarederror',\n    colsample_bytree = 0.3,\n    learning_rate = 0.1,\n    max_depth = 10,\n    alpha = 10,\n    n_estimators = 50\n)\n\n\nxgb_model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric='rmse', verbose=True)\n\n# Evaluate the model using mean squared error and R-squared\ny_pred = xgb_model.predict(X_test)\nmse = mean_squared_error(y_test, y_pred)\nr2 = r2_score(y_test, y_pred)\n\nprint(\"Mean Squared Error:\", mse)\nprint(\"R-squared:\", r2)","metadata":{"execution":{"iopub.status.busy":"2023-03-28T12:51:12.243882Z","iopub.execute_input":"2023-03-28T12:51:12.244888Z","iopub.status.idle":"2023-03-28T12:51:38.633793Z","shell.execute_reply.started":"2023-03-28T12:51:12.244837Z","shell.execute_reply":"2023-03-28T12:51:38.632411Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n  UserWarning,\n","output_type":"stream"},{"name":"stdout","text":"[0]\tvalidation_0-rmse:26069.03462\tvalidation_1-rmse:28496.68189\n[1]\tvalidation_0-rmse:24098.24218\tvalidation_1-rmse:26777.23807\n[2]\tvalidation_0-rmse:21755.27655\tvalidation_1-rmse:24317.87336\n[3]\tvalidation_0-rmse:19644.08952\tvalidation_1-rmse:22129.19291\n[4]\tvalidation_0-rmse:18316.87227\tvalidation_1-rmse:20949.70436\n[5]\tvalidation_0-rmse:17024.29248\tvalidation_1-rmse:19808.72150\n[6]\tvalidation_0-rmse:15877.85063\tvalidation_1-rmse:18966.09785\n[7]\tvalidation_0-rmse:14820.51238\tvalidation_1-rmse:18105.94693\n[8]\tvalidation_0-rmse:14631.97231\tvalidation_1-rmse:18000.71449\n[9]\tvalidation_0-rmse:13239.36826\tvalidation_1-rmse:16508.60319\n[10]\tvalidation_0-rmse:13103.80522\tvalidation_1-rmse:16440.29180\n[11]\tvalidation_0-rmse:12323.76337\tvalidation_1-rmse:15886.20061\n[12]\tvalidation_0-rmse:11165.74545\tvalidation_1-rmse:14649.98311\n[13]\tvalidation_0-rmse:11010.82845\tvalidation_1-rmse:14605.59859\n[14]\tvalidation_0-rmse:9993.35618\tvalidation_1-rmse:13518.40047\n[15]\tvalidation_0-rmse:9446.02818\tvalidation_1-rmse:13138.95767\n[16]\tvalidation_0-rmse:8886.40619\tvalidation_1-rmse:12728.95253\n[17]\tvalidation_0-rmse:8371.08554\tvalidation_1-rmse:12335.47399\n[18]\tvalidation_0-rmse:7635.11041\tvalidation_1-rmse:11527.73637\n[19]\tvalidation_0-rmse:7258.88914\tvalidation_1-rmse:11198.18472\n[20]\tvalidation_0-rmse:6842.38342\tvalidation_1-rmse:10961.55091\n[21]\tvalidation_0-rmse:6482.45468\tvalidation_1-rmse:10750.94017\n[22]\tvalidation_0-rmse:6182.16165\tvalidation_1-rmse:10548.79053\n[23]\tvalidation_0-rmse:5892.97987\tvalidation_1-rmse:10366.33872\n[24]\tvalidation_0-rmse:5627.61131\tvalidation_1-rmse:10219.38665\n[25]\tvalidation_0-rmse:5406.14020\tvalidation_1-rmse:10132.97521\n[26]\tvalidation_0-rmse:5357.43339\tvalidation_1-rmse:10113.14675\n[27]\tvalidation_0-rmse:5137.10802\tvalidation_1-rmse:10019.68120\n[28]\tvalidation_0-rmse:4691.57315\tvalidation_1-rmse:9552.86163\n[29]\tvalidation_0-rmse:4528.29604\tvalidation_1-rmse:9479.35724\n[30]\tvalidation_0-rmse:4335.63229\tvalidation_1-rmse:9382.03752\n[31]\tvalidation_0-rmse:3977.58580\tvalidation_1-rmse:9021.84559\n[32]\tvalidation_0-rmse:3813.95113\tvalidation_1-rmse:8940.48630\n[33]\tvalidation_0-rmse:3796.37452\tvalidation_1-rmse:8936.02825\n[34]\tvalidation_0-rmse:3671.82621\tvalidation_1-rmse:8878.27085\n[35]\tvalidation_0-rmse:3375.99696\tvalidation_1-rmse:8576.85144\n[36]\tvalidation_0-rmse:3259.59042\tvalidation_1-rmse:8536.47062\n[37]\tvalidation_0-rmse:3133.30725\tvalidation_1-rmse:8473.14625\n[38]\tvalidation_0-rmse:3031.17472\tvalidation_1-rmse:8418.69140\n[39]\tvalidation_0-rmse:2806.01562\tvalidation_1-rmse:8200.31620\n[40]\tvalidation_0-rmse:2711.13326\tvalidation_1-rmse:8148.14830\n[41]\tvalidation_0-rmse:2644.28448\tvalidation_1-rmse:8125.68624\n[42]\tvalidation_0-rmse:2632.94502\tvalidation_1-rmse:8122.02579\n[43]\tvalidation_0-rmse:2566.16953\tvalidation_1-rmse:8099.34011\n[44]\tvalidation_0-rmse:2558.30445\tvalidation_1-rmse:8097.36915\n[45]\tvalidation_0-rmse:2483.90566\tvalidation_1-rmse:8071.89002\n[46]\tvalidation_0-rmse:2306.20108\tvalidation_1-rmse:7904.28580\n[47]\tvalidation_0-rmse:2241.95656\tvalidation_1-rmse:7879.74049\n[48]\tvalidation_0-rmse:2228.16283\tvalidation_1-rmse:7877.80181\n[49]\tvalidation_0-rmse:2173.95483\tvalidation_1-rmse:7864.13924\nMean Squared Error: 61844686.001697\nR-squared: 0.9203834065424941\n","output_type":"stream"}]}]}